user  nginx;

# There should be one worker process for each CPU core
worker_processes  1;

# This depends on confinguring the following OS settings:
#  /etc/security/limits.conf
#     nginx soft nofile 60000
#     nginx hard nofile 60000
#  /etc/default/nginx
#     ULIMIT="-n 60000"
worker_rlimit_nofile 60000;

pid        /var/run/nginx.pid;

events {
  # worker_connections sets the number of connections served per worker process
  # clients = worker_connections * worker_processes;
  # This should be equal to "ulimit -n"
  worker_connections  60000;

  # Allow processes to accept multiple connections
  multi_accept on;

  # epoll is the recommended processing method for Linux
  use epoll;
}

http {
  include       /etc/nginx/mime.types;
  default_type  application/octet-stream;

  ########################
  #       Logging
  ########################

  # Disable access_log for to reduce system file usage
  access_log off;
  # Only log critical errors
  error_log /var/log/nginx/error.log crit;

  # For debugging, uncomment following lines and comment out the access_log line above
  # log_format  main  '"$request" $status $body_bytes_sent "$http_referer"';
  # access_log  /var/log/nginx/access.log  main;
  # access_log on;

  ########################
  #   Data Transmission
  ########################

  # Optimize the serving of static files
  sendfile     on;
  # Allow nginx to optimize the amount of data sent at once
  tcp_nopush   on;
  # Send whatever data is available as soon as it's available
  tcp_nodelay  on;


  ########################
  #       Buffers
  ########################

  # Increase buffer sizes to prevent Nginx from writing temp files to disk
  client_body_buffer_size 10K;
  client_header_buffer_size 1k;
  client_max_body_size 8m;
  large_client_header_buffers 2 1k;


  ########################
  #       Timeouts
  ########################

  # Send the client a 408 Request Timeout status code if the request takes more than 2s
  client_body_timeout     2s;
  client_header_timeout   2s;

  # Close connection after 2 seconds
  keepalive_timeout  2s;

  # Close connection if a client stops responding
  reset_timedout_connection on;

  # Cache information about frequently accessed files
  open_file_cache max=200000 inactive=20s;
  open_file_cache_valid 30s;
  open_file_cache_min_uses 2;
  # Cache errors like 404 - for a load balancer this should be off
  open_file_cache_errors off;

  ########################
  #    Proxy Settings
  ########################

  # Http version to use for proxy requests
  proxy_http_version 1.1;

  # Proxy cache location and settings
  proxy_cache_path  /data/nginx/cache
    levels=1:2
    keys_zone=STATIC:60m
    inactive=24h
    max_size=2000m;

  upstream backend {
    ###########################################################
    #
    #   Upstream servers behind the load balancer go here:
    #
    ###########################################################

    # server backend-server.com;
    # server backend-server.com;
    # server backend-server.com;
    # server backend-server.com;
  }

  server {
    listen       80;
    server_name  localhost;

    # These directives are used to verify whether a request has been
    # cached. Be sure to comment them out in production.
    add_header X-GG-Cache-Status $upstream_cache_status;
    add_header X-GG-Cache-Date $upstream_http_date;

    # Loader.io uses requires serving a file at a specific endpoint for
    # verification. Uncomment this block and create the file
    # /data/www/loaderio-12345678910/index.html
    # location /loaderio-12345678910 {
    #   root /data/www;
    #   index  index.html index.htm;
    # }

    # Redirect API requests to upstream servers
    location /api/reviews {
      proxy_pass  http://backend;
      index  index.html index.htm;

      proxy_set_header       Host $host;
      proxy_buffering        on;
      proxy_cache            STATIC;
      proxy_cache_valid      200  1d;
      proxy_cache_use_stale  error timeout invalid_header updating
                              http_500 http_502 http_503 http_504;
      proxy_ignore_headers "Set-Cookie";
      proxy_hide_header "Set-Cookie";
    }

    # Static files are served from the upstream servers at the root
    # endpoint. Redirect requests ending an id number to the same static
    # files at the root endpoint. This is important so nginx doesn't need
    # to maintain separate caches for /0/index.html ... /9999999/index.html
    location ~ ^/([0-9]+)/(.*)$  {
      proxy_pass  http://backend/$2;
      index  index.html index.htm;

      proxy_set_header       Host $host;
      proxy_buffering        on;
      proxy_cache            STATIC;
      proxy_cache_valid      200  1d;
      proxy_cache_use_stale  error timeout invalid_header updating
                              http_500 http_502 http_503 http_504;
      proxy_ignore_headers "Set-Cookie";
      proxy_hide_header "Set-Cookie";
    }

    # Serve requests that lack a trailing slash
    location ~ ^/([0-9]+)  {
      rewrite ^([^.\?]*[^/])$ $1/ permanent;
    }
  }
}